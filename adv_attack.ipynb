{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 8)\n",
    "mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_MobilNetV2  = tf.keras.applications.MobileNetV2(include_top=True,\n",
    "                                                     weights='imagenet')\n",
    "model_MobilNetV2.trainable = False\n",
    "\n",
    "# ImageNet labels\n",
    "decode_predictions_MobilNetV2 = tf.keras.applications.mobilenet_v2.decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_MobilNet  = tf.keras.applications.MobileNet(include_top=True,weights='imagenet')\n",
    "model_MobilNet.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ResNet101 = tf.keras.applications.ResNet101(include_top=True,\n",
    "                                                     weights='imagenet')\n",
    "model_ResNet101.trainable = False\n",
    "decode_predictions_resnet = tf.keras.applications.resnet.decode_predictions\n",
    "# ImageNet labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inception_v3 = tf.keras.applications.InceptionV3(include_top=True, weights='imagenet')\n",
    "model_inception_v3.trainable = False\n",
    "\n",
    "decode_predictions_inception_v3 = tf.keras.applications.inception_v3.decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_InceptionResNetV2 = tf.keras.applications.InceptionResNetV2(include_top=True,\n",
    "                                                     weights='imagenet')\n",
    "model_InceptionResNetV2.trainable = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_VGG16 = tf.keras.applications.VGG16(include_top=True, weights='imagenet')\n",
    "model_VGG16.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xception = tf.keras.applications.Xception(include_top=True, weights='imagenet')\n",
    "model_xception.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ResNet152 = tf.keras.applications.ResNet152(include_top=True,\n",
    "                                                     weights='imagenet')\n",
    "model_ResNet152.trainable = False\n",
    "\n",
    "decode_predictions_resnet = tf.keras.applications.resnet.decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to preprocess the image so that it can be inputted in MobileNetV2\n",
    "def preprocess(image):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = image/255\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    image = image[None, ...]\n",
    "    return image\n",
    "\n",
    "# Helper function to extract labels from probability vector\n",
    "def get_imagenet_label(probs):\n",
    "    return decode_predictions_MobilNetV2(probs, top=1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = tf.keras.utils.get_file('YellowLabradorLooking_new.jpg', 'https://storage.googleapis.com/download.tensorflow.org/example_images/YellowLabradorLooking_new.jpg')\n",
    "image_raw = tf.io.read_file(image_path)\n",
    "image = tf.image.decode_image(image_raw)\n",
    "\n",
    "image = preprocess(image)\n",
    "image_probs = model_MobilNetV2.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(image[0])\n",
    "_, image_class, class_confidence = get_imagenet_label(image_probs)\n",
    "plt.title('{} : {:.2f}% Confidence'.format(image_class, class_confidence*100))\n",
    "print(image[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "def create_adversarial_pattern(input_image, input_label):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(input_image)\n",
    "        prediction = model_MobilNetV2(input_image)\n",
    "        loss = loss_object(input_label, prediction)\n",
    "\n",
    "    # Get the gradients of the loss w.r.t to the input image.\n",
    "    gradient = tape.gradient(loss, input_image)\n",
    "    # Get the sign of the gradients to create the perturbation\n",
    "    signed_grad = tf.sign(gradient)\n",
    "    return signed_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labrador_retriever_index = 208\n",
    "label = tf.one_hot(labrador_retriever_index, image_probs.shape[-1])\n",
    "label = tf.reshape(label, (1, image_probs.shape[-1]))\n",
    "\n",
    "perturbations = create_adversarial_pattern(image, label)\n",
    "plt.imshow(perturbations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images(image, description):\n",
    "    _, label, confidence = get_imagenet_label(model_MobilNetV2.predict(image))\n",
    "    plt.figure()\n",
    "    plt.imshow(image[0])\n",
    "    plt.title('{} \\n {} : {:.2f}% Confidence'.format(description,\n",
    "                                                   label, confidence*100))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epsilons = [0, 0.01, 0.1, 0.15]\n",
    "descriptions = [('Epsilon = {:0.3f}'.format(eps) if eps else 'Input')\n",
    "                for eps in epsilons]\n",
    "\n",
    "for i, eps in enumerate(epsilons):\n",
    "    adv_x = image + eps*perturbations\n",
    "    adv_x = tf.clip_by_value(adv_x, 0, 1)\n",
    "    display_images(adv_x, descriptions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sneaky_adversarial_MI_FGSM( n, y, steps, eta, lam , model):\n",
    "    print(y.shape)\n",
    "    x = (y + np.ones((y.shape)))/2\n",
    "    x = tf.image.resize(x, (299, 299))\n",
    "    x = x[None, ...]\n",
    "    print(x.shape)\n",
    "    g = np.zeros((1, 299,299,3))\n",
    "    g=tf.convert_to_tensor(g,dtype='float32')\n",
    "    goal = np.zeros((1000, 1))\n",
    "    goal[n]=1\n",
    "    goal=goal.reshape((1,1000))\n",
    "    goal=tf.convert_to_tensor(goal)\n",
    "    alpha=eta/steps\n",
    "    for i in range(steps):\n",
    "        d = grad(x,goal,model)\n",
    "        d_1=tf.norm(d, ord=1)\n",
    "        g = lam * g + d/d_1\n",
    "        g_2=tf.norm( g , ord = 1)\n",
    "        x = x - alpha* tf.sign(g)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "def grad(input_image, input_label,model):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(input_image)\n",
    "        prediction = model(input_image)\n",
    "        loss = loss_object(input_label, prediction)\n",
    "        \n",
    "\n",
    "  # Get the gradients of the loss w.r.t to the input image.\n",
    "    gradient = tape.gradient(loss, input_image)\n",
    "    #Get the sign of the gradients to create the perturbation\n",
    "    #signed_grad = tf.sign(gradient)\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "description = ' ' \n",
    "\n",
    "adv_ex = sneaky_adversarial_MI_FGSM(345, images[12] , 10 , 0.05 , 0  ,model_MobilNetV2 )\n",
    "print(np.argmax(model_MobilNetV2.predict(adv_ex)))\n",
    "#x = (adv_ex[0] + np.ones((adv_ex[0].shape)))/2\n",
    "plt.imshow(adv_ex[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_classes[12]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sneaky_adversarial_FGSM( n, y , eta,  model):\n",
    "    x = (y + np.ones((y.shape)))/2\n",
    "    x = tf.image.resize(x, (299, 299))\n",
    "    x = x[None, ...]\n",
    "    goal = np.zeros((1000, 1))\n",
    "    goal[n]=1\n",
    "    goal=goal.reshape((1,1000))\n",
    "    goal=tf.convert_to_tensor(goal)\n",
    "    adv = x - eta * tf.sign(grad(x , goal , model ))\n",
    "    return adv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_ex = sneaky_adversarial_FGSM(2, images[62] , 0.05  ,model_InceptionResNetV2 )\n",
    "print(np.argmax(model_InceptionResNetV2.predict(adv_ex)))\n",
    "#x = (adv_ex[0] + np.ones((adv_ex[0].shape)))/2\n",
    "plt.imshow(adv_ex[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_TV(input_image):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(input_image)\n",
    "        func = TV(input_image)\n",
    "    gradient = tape.gradient(func, input_image)\n",
    "    #Get the sign of the gradients to create the perturbation\n",
    "    #signed_grad \n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = (images[123] + np.ones((images[123].shape)))/2\n",
    "x = tf.image.resize(x, (299, 299))\n",
    "x = x[None, ...]\n",
    "print(np.argmax(model_inception_v3.predict(x)))\n",
    "show_image(images[123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sneaky_adversarial( n, x_target, steps, eta, lam , model):\n",
    "\n",
    "    #x=-1.*np.random.sample((1,224,224,3))\n",
    "    x=-1.*np.ones((1,224,224,3))\n",
    "    M = np.zeros((1,224,224,3))\n",
    "    for i in range(25):\n",
    "        for j in range(3):\n",
    "            for k in range(25):\n",
    "                M[0,i+45,k+45,j]=1. \n",
    "    M = tf.convert_to_tensor(M,dtype='float32')\n",
    "    x=tf.convert_to_tensor(x,dtype='float32')\n",
    "    x_t = (x_target + np.ones((x_target.shape)))/2\n",
    "    x_t = tf.image.resize(x_t, (224, 224))\n",
    "    #x_t = x_t[None, ...]\n",
    "    #x_t = cm(x_t,M1)\n",
    "    goal = np.zeros((1000, 1))\n",
    "    goal[n]=1    \n",
    "    goal=goal.reshape((1,1000))\n",
    "    goal=tf.convert_to_tensor(goal)\n",
    "\n",
    "    for i in range(steps):\n",
    "\n",
    "        d = grad(cm(x,M)+x_t , goal , model)                \n",
    "        x -= eta * (d + lam * (cm(x,M)))\n",
    "        \n",
    "\n",
    "    return cm(x,M)+x_t,cm(x,M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sneaky_adversarial_sett( n, x_target, steps, eta, lam , model):\n",
    "\n",
    "    x=np.random.sample((1,299,299,3))\n",
    "    x=tf.convert_to_tensor(x,dtype='float32')\n",
    "    x_t = (x_target + np.ones((x_target.shape)))/2\n",
    "    x_t = tf.image.resize(x_t, (299, 299))\n",
    "    #x = x[None, ...]\n",
    "    goal = np.zeros((1000, 1))\n",
    "    goal[n]=1    \n",
    "    goal=goal.reshape((1,1000))\n",
    "    goal=tf.convert_to_tensor(goal)\n",
    "\n",
    "    for i in range(steps):\n",
    "\n",
    "        d = grad(x+x_t , goal , model)                \n",
    "        x -= eta * (d*0.1 + lam * x)\n",
    "        \n",
    "\n",
    "    return x+x_t,x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_ex ,pret = sneaky_adversarial_sett(6, images[12] ,30 , 1 , 0.12  ,model_inception_v3 )\n",
    "pred = model_inception_v3.predict(adv_ex)\n",
    "print(np.argmax(pred))\n",
    "print(pred.max())\n",
    "#x = (adv_ex[0] + np.ones((adv_ex[0].shape)))/2\n",
    "plt.imshow(adv_ex[0]) \n",
    "plt.show()\n",
    "plt.imshow(pret[0]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.ones((1,224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm(X,M2):\n",
    "    x = X.numpy()\n",
    "    m = M2.numpy()\n",
    "    for i in range(224):\n",
    "        for j in range(224):\n",
    "            for k in range(3):\n",
    "                x[0,i,j,k] = m[0,i,j,k]*x[0,i,j,k]\n",
    "    X = tf.convert_to_tensor(x,dtype='float32')\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def med(X):\n",
    "    x = X.numpy()\n",
    "    s = x.sum()\n",
    "    for i in range(224):\n",
    "        for j in range(224):\n",
    "            for k in range(3):\n",
    "                x[0,i,j,k] = x[0,i,j,k]\n",
    "    X = tf.convert_to_tensor(x,dtype='float32')\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TV(X):\n",
    "    x = X.numpy()\n",
    "    t = 0\n",
    "    for i in range(224):\n",
    "        for j in range(224):\n",
    "            for k in range(3):\n",
    "                t = t + ((x[0,i,j,k]-x[0,i,j-1,k])**2+(x[0,i-1,j,k]-x[0,i,j,k])**2)**(1/2)\n",
    "    t = tf.convert_to_tensor(t,dtype='float')\n",
    "    return t\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.image.resize(((images[176] + np.ones((images[176].shape)))/2), (224, 224))\n",
    "x = x[None, ...]\n",
    "print(np.argmax(model_MobilNetV2.predict(x)))\n",
    "print(model_MobilNetV2.predict(x).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 71\n",
    "adv_ex ,pret = sneaky_adversarial(111, images[i] ,20 , 1 , 0.12  ,model_MobilNetV2 )\n",
    "pred = model_MobilNetV2.predict(adv_ex)\n",
    "print(np.argmax(pred))\n",
    "print(pred.max())\n",
    "#x = (adv_ex[0] + np.ones((adv_ex[0].shape)))/2\n",
    "plt.imshow(adv_ex[0]) \n",
    "plt.show()\n",
    "plt.imshow(pret[0]) \n",
    "plt.show()\n",
    "im=cv2.blur(pret[0].numpy(), ksize=(2, 2))\n",
    "plt.imshow(adv_ex[0]-pret[0]+im)\n",
    "print(np.argmax(model_MobilNetV2.predict(adv_ex[0]-pret[0]+im.reshape((1,224,224,3)))))\n",
    "print(model_MobilNetV2.predict(adv_ex[0]-pret[0]+im.reshape((1,224,224,3))).max())\n",
    "plt.show()\n",
    "print(true_classes[i] - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.image.resize(images[5], (224, 224))\n",
    "x = x[None, ...]\n",
    "print(np.argmax(model_ResNet101.predict(x)))\n",
    "show_image(images[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data():\n",
    "    \"\"\"\n",
    "    n : integer\n",
    "        number of adversarial examples to generate\n",
    "    data : list of tuples\n",
    "        data set to generate adversarial examples using\n",
    "    \"\"\"\n",
    "    # Our augmented training set:\n",
    "    augmented = []\n",
    "       \n",
    "    for i in range(200):\n",
    "        # Progress \"bar\"\n",
    "        if i % 2 == 0:\n",
    "            print(\"Generated images: \" + str(i))\n",
    "            \n",
    "        y_fake = np.random.randint(1000)\n",
    "        \n",
    "        adv_ex = sneaky_adversarial_FGSM(y_fake , images[i] , 0.05   , model_inception_v3 )\n",
    "        \n",
    "        y_actual = true_classes[i] - 1\n",
    "        \n",
    "        augmented.append(( adv_ex , y_fake , y_actual ))\n",
    "        \n",
    "    return augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakedata_FGSM_for_model_inception_v3=augment_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data_L_BFGS():\n",
    "    \"\"\"\n",
    "    n : integer\n",
    "        number of adversarial examples to generate\n",
    "    data : list of tuples\n",
    "        data set to generate adversarial examples using\n",
    "    \"\"\"\n",
    "    # Our augmented training set:\n",
    "    augmented = []\n",
    "       \n",
    "    for i in range(200):\n",
    "        # Progress \"bar\"\n",
    "        if i % 10 == 0:\n",
    "            print(\"Generated images: \" + str(i))\n",
    "            \n",
    "        y_fake = np.random.randint(1000)\n",
    "        \n",
    "        adv_ex ,pret = sneaky_adversarial_sett(y_fake, images[i] ,30 , 1 , 0.12  ,model_inception_v3 )\n",
    "        \n",
    "        y_actual = true_classes[i] - 1\n",
    "        \n",
    "        augmented.append(( adv_ex , y_fake , y_actual ))\n",
    "        \n",
    "    return augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data_I_FGSM():\n",
    "    \"\"\"\n",
    "    n : integer\n",
    "        number of adversarial examples to generate\n",
    "    data : list of tuples\n",
    "        data set to generate adversarial examples using\n",
    "    \"\"\"\n",
    "    # Our augmented training set:\n",
    "    augmented = []\n",
    "       \n",
    "    for i in range(200):\n",
    "        # Progress \"bar\"\n",
    "        if i % 10 == 0:\n",
    "            print(\"Generated images: \" + str(i))\n",
    "            \n",
    "        y_fake = np.random.randint(1000)\n",
    "        \n",
    "        adv_ex = sneaky_adversarial_MI_FGSM(y_fake, images[i] , 10 , 0.05 , 0  ,model_inception_v3 )\n",
    "        \n",
    "        y_actual = true_classes[i] - 1\n",
    "        \n",
    "        augmented.append(( adv_ex , y_fake , y_actual ))\n",
    "        \n",
    "    return augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data_MI_FGSM():\n",
    "    \"\"\"\n",
    "    n : integer\n",
    "        number of adversarial examples to generate\n",
    "    data : list of tuples\n",
    "        data set to generate adversarial examples using\n",
    "    \"\"\"\n",
    "    # Our augmented training set:\n",
    "    augmented = []\n",
    "       \n",
    "    for i in range(200):\n",
    "        # Progress \"bar\"\n",
    "        if i % 10 == 0:\n",
    "            print(\"Generated images: \" + str(i))\n",
    "            \n",
    "        y_fake = np.random.randint(1000)\n",
    "        \n",
    "        adv_ex = sneaky_adversarial_MI_FGSM(y_fake, images[i] , 10 , 0.05 , 1  ,model_inception_v3 )\n",
    "        \n",
    "        y_actual = true_classes[i] - 1\n",
    "        \n",
    "        augmented.append(( adv_ex , y_fake , y_actual ))\n",
    "        \n",
    "    return augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakedata_MI_FGSM = augment_data_MI_FGSM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakedata_L_BFGS = augment_data_L_BFGS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakedata_I_FGSM = augment_data_I_FGSM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy( test_data):\n",
    "    tot = 200\n",
    "    correct1 = 0\n",
    "    correct2 = 0\n",
    "    correct3 = 0\n",
    "    correct4 = 0\n",
    "    correct5 = 0\n",
    "    for i in range(200):\n",
    "        if i % 20 == 0:\n",
    "            print(i)\n",
    "        label1 = np.argmax(model_xception.predict(tf.image.resize(test_data[i][0], (299, 299))))\n",
    "        label2 = np.argmax(model_InceptionResNetV2.predict(tf.image.resize(test_data[i][0], (299, 299))))\n",
    "        label3 = np.argmax(model_inception_v3.predict(tf.image.resize(test_data[i][0], (299, 299))))\n",
    "        label4 = np.argmax(model_MobilNetV2.predict(tf.image.resize(test_data[i][0], (224, 224))))\n",
    "        label5 = np.argmax(model_MobilNet.predict(tf.image.resize(test_data[i][0], (224, 224))))\n",
    "        correct1 += int((label1) == test_data[i][2])\n",
    "        correct2 += int((label2) == test_data[i][2])\n",
    "        correct3 += int((label3) == test_data[i][2])\n",
    "        correct4 += int((label4) == test_data[i][2])\n",
    "        correct5 += int((label5) == test_data[i][2])\n",
    "    print('Accuracy: model_xception '+str(correct1/tot))\n",
    "    print('Accuracy: model_InceptionResNetV2 '+str(correct2/tot))\n",
    "    print('Accuracy: model_inception_v3 '+str(correct3/tot))\n",
    "    print('Accuracy: model_MobilNetV2 '+str(correct4/tot))\n",
    "    print('Accuracy: model_MobilNet '+str(correct5/tot))\n",
    "    return correct1 / tot , correct2 / tot , correct3 / tot , correct4 / tot, correct5 / tot\n",
    "\n",
    "print('Accuracy: ' + str(accuracy(fakedata_MI_FGSM)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(fakedata_L_BFGS[2][0].numpy().reshape((299,299,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(fakedata_MI_FGSM[101][0][0])\n",
    "print(np.max(model_MobilNetV2.predict(fakedata_MI_FGSM[101][0])))\n",
    "toster = tf.image.resize(images[101], (224, 224))\n",
    "toster = toster[None, ...]\n",
    "print(np.max(model_MobilNetV2.predict(toster)))\n",
    "print(np.argmax(model_MobilNetV2.predict(toster)))\n",
    "print(fakedata_MI_FGSM[101][1])\n",
    "print(fakedata_MI_FGSM[101][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd nips-2017-adversarial-learning-development-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from io import BytesIO\n",
    "import IPython.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import scipy\n",
    "import imageio\n",
    "tensorflow_master = \"\"\n",
    "input_dir         = \"../nips-2017-adversarial-learning-development-set/images/\"\n",
    "max_epsilon       = 16.0\n",
    "image_width       = 299\n",
    "image_height      = 299\n",
    "batch_size        = 200\n",
    "\n",
    "eps = 2.0 * max_epsilon / 255.0\n",
    "batch_shape = [batch_size, image_height, image_width, 3]\n",
    "num_classes = 1001\n",
    "\n",
    "def load_images(input_dir, batch_shape):\n",
    "    images = np.zeros(batch_shape)\n",
    "    filenames = []\n",
    "    idx = 0\n",
    "    batch_size = batch_shape[0]\n",
    "    for filepath in sorted(tfv1.gfile.Glob(os.path.join(input_dir, '*.png'))):\n",
    "        with tfv1.gfile.Open(filepath, \"rb\") as f:\n",
    "            images[idx, :, :, :] = imageio.imread(f, pilmode='RGB').astype(np.float)*2.0/255.0 - 1.0\n",
    "        filenames.append(os.path.basename(filepath))\n",
    "        idx += 1\n",
    "        if idx == batch_size:\n",
    "            yield filenames, images\n",
    "            filenames = []\n",
    "            images = np.zeros(batch_shape)\n",
    "            idx = 0\n",
    "    if idx > 0:\n",
    "        yield filenames, images\n",
    "\n",
    "def show_image(a, fmt='png'):\n",
    "    a = np.uint8((a+1.0)/2.0*255.0)\n",
    "    f = BytesIO()\n",
    "    Image.fromarray(a).save(f, fmt)\n",
    "    IPython.display.display(IPython.display.Image(data=f.getvalue()))\n",
    "\n",
    "class InceptionModel(object):\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        self.built = False\n",
    "\n",
    "    def __call__(self, x_input):\n",
    "        \"\"\"Constructs model and return probabilities for given input.\"\"\"\n",
    "        reuse = True if self.built else None\n",
    "        with slim.arg_scope(inception.inception_v3_arg_scope()):\n",
    "            _, end_points = inception.inception_v3(\n",
    "                            x_input, num_classes=self.num_classes, is_training=False,\n",
    "                            reuse=reuse)\n",
    "        self.built = True\n",
    "        output = end_points['Predictions']\n",
    "        probs = output.op.inputs[0]\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tfv1  # for TF 2\n",
    "\n",
    "#tf.disable_v2_behavior()  # for TF 2\n",
    "categories = pd.read_csv(\"categories.csv\")\n",
    "image_classes = pd.read_csv(\"images.csv\")\n",
    "image_iterator = load_images(input_dir, batch_shape)\n",
    "\n",
    "# get first batch of images\n",
    "filenames, images = next(image_iterator)\n",
    "\n",
    "image_metadata = pd.DataFrame({\"ImageId\": [f[:-4] for f in filenames]}).merge(image_classes,\n",
    "                                                                              on=\"ImageId\")\n",
    "true_classes = image_metadata[\"TrueLabel\"].tolist()\n",
    "target_classes = true_labels = image_metadata[\"TargetClass\"].tolist()\n",
    "true_classes_names = (pd.DataFrame({\"CategoryId\": true_classes})\n",
    "                        .merge(categories, on=\"CategoryId\")[\"CategoryName\"].tolist())\n",
    "target_classes_names = (pd.DataFrame({\"CategoryId\": target_classes})\n",
    "                          .merge(categories, on=\"CategoryId\")[\"CategoryName\"].tolist())\n",
    "\n",
    "print(\"Here's an example of one of the images in the development set\")\n",
    "show_image(images[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "true_classes_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(images[101])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
